{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaj/anaconda3/envs/datathon/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  service_score\n",
      "0  While I was sad to see Bibo close at this loca...           0.50\n",
      "1  Friendly baristas and great coffee. Since thei...           0.80\n",
      "2  Love their coffee and vibe. The breakfast food...           0.60\n",
      "3  It's like everything you try is your new favor...           0.90\n",
      "4  This is probably one of my favorite boba place...           0.95\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_DATA_PATH = '/Users/nikolaj/Desktop/datathon/review_chunks/score_training.csv'\n",
    "use_cols = [\"text\", \"service_score\"]\n",
    "\n",
    "df = pd.read_csv(TRAIN_DATA_PATH, usecols=use_cols)\n",
    "train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "eval_dataset = Dataset.from_pandas(eval_df.reset_index(drop=True))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 240/240 [00:00<00:00, 2924.22 examples/s]\n",
      "Map: 100%|██████████| 60/60 [00:00<00:00, 2947.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "train_tokenized = train_dataset.map(\n",
    "    lambda example: tokenizer(\n",
    "        str(example[\"text\"]),\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    ),\n",
    "    # remove_columns=[\"text\", \"yumminess_score\"]\n",
    ")\n",
    "eval_tokenized = eval_dataset.map(\n",
    "    lambda example: tokenizer(\n",
    "        str(example[\"text\"]),\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    ),\n",
    "    # remove_columns=[\"text\", \"yumminess_score\"]\n",
    ")\n",
    "\n",
    "train_tokenized = train_tokenized.rename_column(\"service_score\", \"labels\")\n",
    "eval_tokenized = eval_tokenized.rename_column(\"service_score\", \"labels\")\n",
    "train_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "eval_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45, training_loss=0.06894283294677735, metrics={'train_runtime': 37.6703, 'train_samples_per_second': 19.113, 'train_steps_per_second': 1.195, 'total_flos': 23843706531840.0, 'train_loss': 0.06894283294677735, 'epoch': 3.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import accelerate\n",
    "from torch import nn\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = nn.MSELoss()\n",
    "        loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    num_labels=1,  # Single output for regression\n",
    "    problem_type=\"regression\"  # Specify this is a regression task\n",
    ")\n",
    "\n",
    "# Configure training arguments with compatible options\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./service_model\",\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    save_steps=500,\n",
    ")\n",
    "\n",
    "# Add labels to the dataset\n",
    "def add_labels(example):\n",
    "    example['labels'] = example['service_score']\n",
    "    return example\n",
    "\n",
    "\n",
    "# Use the custom RegressionTrainer instead of the standard Trainer\n",
    "trainer = RegressionTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.4845851957798004}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier_service = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "review = \"As a whole, customer service in IV sucks. But, my caramel latte tonight was very very good. I owe it to the barista. I guess my last experience was bad due to the employee. But this guy made my latte with a beautiful heart and thankfully it made fall in love with their lattes. Now I won't have to to to French Press as often ;)\"\n",
    "classifier_service(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_service.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assume classifier has been trained already\n",
    "joblib.dump(classifier_service, \"classifier_service.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
